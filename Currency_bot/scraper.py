import datetime

import requests
from bs4 import BeautifulSoup
import sqlite3

url_dollar = 'https://www.tgju.org/profile/price_dollar_rl'

urls = {
    'Ø¯Ù„Ø§Ø±': 'https://www.tgju.org/profile/price_dollar_rl',
    'Ø¯Ù„Ø§Ø± Ú©Ø§Ù†Ø§Ø¯Ø§': 'https://www.tgju.org/profile/price_dollar_rl',
    'ÛŒÙˆØ±Ùˆ': 'https://www.tgju.org/profile/price_eur',
    'Ù¾ÙˆÙ†Ø¯ Ø§Ù†Ú¯Ù„ÛŒØ³': 'https://www.tgju.org/profile/price_gbp',
    'Ø·Ù„Ø§ 18 Ø¹ÛŒØ§Ø±': 'https://www.tgju.org/profile/geram18',
    'Ø·Ù„Ø§ 24 Ø¹ÛŒØ§Ø±': 'https://www.tgju.org/profile/geram24',
    'Ù…Ø«Ù‚Ø§Ù„ Ø·Ù„Ø§': 'https://www.tgju.org/profile/mesghal',
    'Ø³Ú©Ù‡ Ø§Ù…Ø§Ù…ÛŒ': 'https://www.tgju.org/profile/sekee',
    'Ø³Ú©Ù‡ Ø¨Ù‡Ø§Ø± Ø¢Ø²Ø§Ø¯ÛŒ': 'https://www.tgju.org/profile/sekeb',

}

def get_dollar_price():
    response = requests.get(urls['Ø¯Ù„Ø§Ø±'])

    if response.status_code != 200:
        return "Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª âŒ"

    soup = BeautifulSoup(response.text, 'html.parser')

    price_tag = soup.find('span[data-col="info.last_trade.PDrCotVal"]')

    if price_tag:
        return f"ğŸ’µ Ù‚ÛŒÙ…Øª Ø¯Ù„Ø§Ø±: {price_tag.text.strip()} ØªÙˆÙ…Ø§Ù†"
    else:
        return "Ù‚ÛŒÙ…Øª Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯ âŒ"


def get_price(url):
    response = requests.get(url)
    # print(response.status_code)
    soup = BeautifulSoup(response.text, 'html.parser') if response.status_code == 200 else None
    price_tag = soup.find('span', class_='value')
    # print(type(price_tag.text.strip()))
    # if price_tag:
    #     price = price_tag.text.strip().split('\n')
    #     return price
    # else:
    #     return "âŒ Ù‚ÛŒÙ…Øª Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯"

    return price_tag.text.strip().split("\n")[0] if price_tag else "âŒ Ù‚ÛŒÙ…Øª Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯"
    # for name, price in price_tag:
    #     print(name, price)


def get_all_prices():
    prices = {name: get_price(url) for name, url in urls.items()}
    return prices


def get_dates_prices():
    response = requests.get(urls['Ø¯Ù„Ø§Ø±'])

    # if response.status_code !=200:
    #     return "Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª âŒ"
    soup = BeautifulSoup(response.text,'html.parser') if response.status_code ==200 else None

def get_last_5_days_prices():
    url = 'https://www.tgju.org/profile/geram18/history'

    try:
        response = requests.get(url)
        table = BeautifulSoup(response.text, 'html.parser') if response.status_code == 200 else None # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø¬Ø¯ÙˆÙ„
        rows = table.find('table').find_all('tr',limit=6) # Ú¯Ø±ÙØªÙ† 6 Ø³Ø·Ø± Ø¢Ø®Ø±

        prices = {}

        for row in rows:
            columns = row.find_all('td')

            if len(columns) <4: # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø­Ø¯Ø§Ù‚Ù„ Û´ Ø³ØªÙˆÙ† Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯
                continue

            final_price = columns[3].text.strip().replace(',','')
            date = columns[-1].text.strip()

            try:
                prices[date] = int(final_price)
            except ValueError:
                continue
        return prices
    except requests.exceptions.RequestException as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§: {e}")
        return {}

pricess = get_last_5_days_prices()
print(pricess)

def save_prices_to_database(prices:dict):
    conn = sqlite3.connect('prices.db')
    cursor = conn.cursor()


    for name,price in prices.items():
        timestamp = datetime.now()


if __name__ == "__main__":
    print(get_all_prices())
    # print(get_dates_prices())
